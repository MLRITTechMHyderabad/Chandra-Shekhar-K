
HDFS- hadoop distributed file system

In distributed system, we cannot edit the files 

default block size:- 128mb


w


CORE COMPONENTS OF HADOOP

HDFS -> hadoop distributed file system / distributed,fault-tolerant storage system

YARN -> resource manager for job scheduling and cluster resource manager

MapReduce -> programming model for processing datasets in parallel

Hive -> SQL like query engine for hadoop

pig -> scripting language for large datasets and useful for semi and unstructered data 

HBase -> NoSQL database on top of HDFS for real time reads/writes
 
sqoop -> Imports and exports data between hadoop and RDBMS

FLUME -> collects log and event data for ingestion into HDFS


HADOOP ECOSYSTEM FLOW 

flow:-
        * sqoop ingest data into HDFS
        * HDFS stores RAW data
        * YARN schedules jobs and allocates cluster resources
        * MapReduce process data in parallel
        * Hive ,pig,or HBase are used to query or manage data (insert data)




HDFS -Architecture

NameNode is MASTER
    acts as meta data server
    stores namespace info (filenames,directories)
    manages block locations and file-to-block mapping
    uses FsImage and Editlog for metadata persistence

DataNode is a Slave
    Stores actual file data in blocks (size: 128mb )
    sends hearetbeats and block reports
    each block is replicated for fault tolerance

FsImage
     a snapshot of the filesystem metadata
     stored on the NameNode
     loaded into memory at NameNode startup

EditLog 
    it stores recent metadata changes
    helps to recover metadata by replaying changes on FsImage during restart

Secondary NameNode
    periodically merges FsImage and EditLog to reduce NameNode memory load.
    it is not a backup NameNode.


NOTE: 
    there is exception ,we can create ACID properties enabaled tables inside Hive


hearetbeat is simple java program is used to send the signals

vertical scaling: adding more power to the existing system -> vcertical

horizantal :- 